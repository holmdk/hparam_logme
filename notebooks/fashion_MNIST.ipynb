{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8bfef88",
   "metadata": {},
   "source": [
    "# ResNet Pytorch implementation for FashionMNIST classification\n",
    "First we import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5353fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import tqdm as tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "from utils.LogME import LogME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91874252",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "[FreezeOut](https://github.com/ajbrock/FreezeOut)\n",
    "\n",
    "[RandomErasing](https://github.com/zhunzhong07/Random-Erasing)   \n",
    "\n",
    "- `transforms.RandomErasing(probability = args.p, sh = args.sh, r1 = args.r1, mean = [0.4914]),`\n",
    "\n",
    "Other datasets: \n",
    "- CIFAR10\n",
    "- ImageNet?\n",
    "- Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad524d1",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71cc0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 40\n",
    "augmentation = True\n",
    "logme_test = False\n",
    "use_pretrained = True\n",
    "in_chan = 3 if use_pretrained else 1\n",
    "train_val_split = 0.8\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4373969e",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "We can load data from pytorch dataset and preprocess it using transform function.\n",
    "\n",
    "Note that the ResNet implemented in torchvision take RGB images as inputs, which has three channels. So, here we repeat the single-channel grey scale digits image three times to fit the torchvision model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c3a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle indices\n",
    "indices = np.arange(60000)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_val_split = round((len(indices) * train_val_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87415b8a",
   "metadata": {},
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a266217",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mean = 0.2854  # try 0.1307   # 0.2854\n",
    "norm_std = 0.3528   # try 0.3081   #0.3528\n",
    "normalize = transforms.Normalize((norm_mean,), (norm_std,))\n",
    "expand_transform = transforms.Lambda(lambda x: x.repeat(3, 1, 1))\n",
    "\n",
    "# norm_mean = torch.mean(mnist_train.dataset.data[mnist_train.indices] / 255.)  # 0.1307, 0.3081 also used\n",
    "# norm_std = torch.std(mnist_train.dataset.data[mnist_train.indices] / 255.)\n",
    "\n",
    "\n",
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],   # IMAGENET FOR PRETRAINED MODEL\n",
    "#                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "if augmentation:\n",
    "    # Prepare transforms and data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        # transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomCrop(28, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "else:\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "        #expand_transform\n",
    "    ])\n",
    "    \n",
    "test_transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "    #expand_transform\n",
    "])\n",
    "\n",
    "if use_pretrained:\n",
    "    train_transform.transforms.append(expand_transform)\n",
    "    test_transform.transforms.append(expand_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5945fa",
   "metadata": {},
   "source": [
    "### Datasets and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7fb432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Holm\\anaconda3\\envs\\inpainting_project\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000 10000\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "## Train\n",
    "mnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size,\n",
    "    shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:train_val_split]), num_workers=num_workers)\n",
    "\n",
    "## Val\n",
    "mnist_val = datasets.FashionMNIST(root='./data', train=True, download=True, transform=test_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(mnist_val, batch_size=batch_size,\n",
    "    shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[train_val_split:]))\n",
    "\n",
    "## Test\n",
    "mnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size,\n",
    "    shuffle=False, num_workers=num_workers)\n",
    "\n",
    "## sizes\n",
    "print(train_val_split, len(mnist_train) - train_val_split, len(mnist_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc77f02",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9346d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cmasch/zalando-fashion-mnist/blob/master/Simple_Convolutional_Neural_Network_Fashion-MNIST.ipynb\n",
    "# This should get around 0.934 accuracy with data augmentation\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 4, padding='same')\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 4)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9239a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pretrained:\n",
    "    # Import the module\n",
    "    import torchvision\n",
    "\n",
    "    # Download resnet18\n",
    "    model = torchvision.models.resnet34(pretrained=True)\n",
    "\n",
    "#     # Freeze all the layers bar the last one\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "    \n",
    "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "else:\n",
    "    model = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa2544",
   "metadata": {},
   "source": [
    "## Optional: LogME test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5bf8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pretrained:\n",
    "    feature_extractor = nn.Sequential(*list(model.children())[:-2])\n",
    "else:\n",
    "    feature_extractor = nn.Sequential(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69eab46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if logme_test:\n",
    "    score_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in train_loader:\n",
    "            if use_pretrained:\n",
    "                features = feature_extractor(x)\n",
    "            else:\n",
    "                features = feature_extractor(x)\n",
    "            score = LogME(features.squeeze(), y)\n",
    "            score_list.append(score)\n",
    "\n",
    "    print('LogME score is {}'.format(np.mean(score_list)))\n",
    "    \n",
    "    del feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "622ea09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        \n",
    "        # accuracy\n",
    "        proba = torch.exp(logits)\n",
    "        pred_class = torch.argmax(proba, dim=1)\n",
    "        acc = (pred_class == y).float().mean()\n",
    "        self.log('val_acc', acc)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        self.log('test_loss', loss)\n",
    "        \n",
    "        # accuracy\n",
    "        proba = torch.exp(logits)\n",
    "        pred_class = torch.argmax(proba, dim=1)\n",
    "        acc = (pred_class == y).float().mean()\n",
    "        self.log('test_acc', acc)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        self.opt = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=0.001)\n",
    "        \n",
    "#         optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.001)\n",
    "\n",
    "        self.reduce_lr_on_plateau = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.opt,\n",
    "            mode='max',\n",
    "            factor=0.1,\n",
    "            patience=3,\n",
    "            verbose=True,\n",
    "#             cooldown=5,\n",
    "            min_lr=1e-8,\n",
    "        )\n",
    "\n",
    "        return {\"optimizer\": self.opt, \"lr_scheduler\": self.reduce_lr_on_plateau, \"monitor\": \"val_acc\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "127faabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Classifier()\n",
    "# x = torch.randn(2, 1, 28, 28)\n",
    "# out = model(x)\n",
    "# x, y = next(iter(train_loader))\n",
    "# out = model(x)\n",
    "# print(out.shape)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546fd768",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a044583",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss')\n",
    "earlystop_callback = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c019c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "C:\\Users\\Holm\\anaconda3\\envs\\inpainting_project\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:597: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  \"GPU available but not used. Set the gpus flag in your trainer\"\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 21.3 M\n",
      "---------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.159    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Holm\\anaconda3\\envs\\inpainting_project\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:103: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n",
      "C:\\Users\\Holm\\anaconda3\\envs\\inpainting_project\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "C:\\Users\\Holm\\anaconda3\\envs\\inpainting_project\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:103: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305697aeb7a74cd58459381fe547da6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Holm\\anaconda3\\envs\\inpainting_project\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:897: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n"
     ]
    }
   ],
   "source": [
    "model = LitMNIST(model)\n",
    "trainer = Trainer(max_epochs=num_epochs, callbacks=[checkpoint_callback, earlystop_callback])\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a42272e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Holm\\anaconda3\\envs\\inpainting_project\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:103: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8991932c48174ecb85c60713ba8afc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.926800012588501, 'test_loss': 0.20335043966770172}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# run test set\n",
    "result = trainer.test(test_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04a883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
